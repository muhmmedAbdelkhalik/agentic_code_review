# LocalAI Code Review Agent Configuration

# Ollama Server Settings (switched from LocalAI for better CPU performance)
localai:
  url: "http://localhost:11434"
  model: "qwen2.5-coder:7b"  # Changed from gemma:2b for better security detection
  temperature: 0.2
  max_tokens: 4000  # Increased from 3000 for more detailed output
  timeout: 120  # Increased from 60 for larger model

# PHP Analysis Tools
tools:
  phpstan:
    enabled: true
    path: "phpstan"
    args: ["analyse", "--error-format=json", "--no-progress"]
  phpcs:
    enabled: true
    path: "phpcs"
    args: ["--report=json", "--standard=PSR12"]
  phpunit:
    enabled: true
    path: "phpunit"
    args: ["--testdox", "--colors=never"]

# Output Settings
output:
  file: ".local_review.json"
  log_file: ".local_review.log"
  verbose: false

# Git Settings
git:
  diff_context: 5  # lines of context around changes
  target_branch: "main"  # default branch to compare against

# Review Behavior
review:
  max_issues: 100
  block_on_critical: true  # set to true to block push on critical issues
  min_confidence: 0.5  # minimum confidence to report an issue

# Severity Levels (for display)
severity:
  critical:
    color: "red"
    symbol: "ðŸ”´"
  high:
    color: "yellow"
    symbol: "ðŸŸ¡"
  medium:
    color: "blue"
    symbol: "ðŸ”µ"
  low:
    color: "green"
    symbol: "ðŸŸ¢"

